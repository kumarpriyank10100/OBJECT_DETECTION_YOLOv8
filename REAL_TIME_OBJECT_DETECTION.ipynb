{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è Real-Time Object Detection with YOLOv8\n",
        "\n",
        "YOLO (You Only Look Once) changed the computer vision landscape by treating detection as a **single regression problem** rather than a classification task performed on thousands of window crops. We are using **YOLOv8**, the most refined version of the architecture, which utilizes a \"Darknet\" backbone and a C2f (Cross Stage Partial Bottleneck with two convolutions) module for superior feature fusion.\n",
        "\n",
        "### üìì Python Implementation (Jupyter Optimized)"
      ],
      "metadata": {
        "id": "9qLyZLRdexJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMF6yfgCfnKA",
        "outputId": "513835ad-71d3-4c22-8dd5-4b1eecb6e3fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.241-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.241-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.241 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import display, Javascript, clear_output\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 1. Initialize YOLOv8\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "def setup_js_webcam():\n",
        "    js = Javascript('''\n",
        "    // We define the function globally immediately\n",
        "    window.takePhoto = async function() {\n",
        "      const div = document.querySelector('#webcam-div') || document.createElement('div');\n",
        "      div.id = 'webcam-div';\n",
        "\n",
        "      const video = document.querySelector('#webcam-video') || document.createElement('video');\n",
        "      video.id = 'webcam-video';\n",
        "\n",
        "      if (!video.srcObject) {\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        video.style.display = 'block';\n",
        "        video.width = 640;\n",
        "        video.height = 480;\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        await video.play();\n",
        "      }\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = 640;\n",
        "      canvas.height = 480;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "      return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    };\n",
        "\n",
        "    // Signal that the script has loaded\n",
        "    window.webcamReady = true;\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    return cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "# --- EXECUTION ---\n",
        "setup_js_webcam()\n",
        "\n",
        "print(\"Waiting for browser to initialize webcam...\")\n",
        "# 2. THE HANDSHAKE: Wait until JS confirms it's ready\n",
        "for i in range(10):\n",
        "    try:\n",
        "        if eval_js('window.webcamReady'):\n",
        "            print(\"Webcam is ready!\")\n",
        "            break\n",
        "    except:\n",
        "        time.sleep(1)\n",
        "        if i == 9:\n",
        "            print(\"Error: Handshake failed. Please check browser permissions.\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        js_reply = eval_js('window.takePhoto()')\n",
        "        if not js_reply: break\n",
        "\n",
        "        frame = js_to_image(js_reply)\n",
        "        results = model.predict(frame, conf=0.5, verbose=False)\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        cv2_imshow(annotated_frame)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Status: {e}\")"
      ],
      "metadata": {
        "id": "fluiEvypie5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from IPython.display import display, Javascript, HTML\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# 1. Initialize YOLOv8\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "def start_live_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "\n",
        "    async function createDom() {\n",
        "        if (div !== null) return;\n",
        "\n",
        "        div = document.createElement('div');\n",
        "        div.style.position = 'relative';\n",
        "\n",
        "        video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        video.width = 640;\n",
        "        video.height = 480;\n",
        "        video.setAttribute('playsinline', '');\n",
        "        video.id = 'video-feed';\n",
        "\n",
        "        // This canvas will sit on top of the video to show detection boxes\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.style.position = 'absolute';\n",
        "        canvas.style.left = '0';\n",
        "        canvas.style.top = '0';\n",
        "        canvas.width = 640;\n",
        "        canvas.height = 480;\n",
        "        canvas.id = 'overlay-canvas';\n",
        "\n",
        "        div.appendChild(video);\n",
        "        div.appendChild(canvas);\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        captureCanvas = document.createElement('canvas');\n",
        "        captureCanvas.width = 640;\n",
        "        captureCanvas.height = 480;\n",
        "    }\n",
        "\n",
        "    async function streamVideo() {\n",
        "        await createDom();\n",
        "        stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        window.videoStream = stream;\n",
        "    }\n",
        "\n",
        "    // Function to capture a frame and send to Python\n",
        "    window.getFrame = async function() {\n",
        "        const context = captureCanvas.getContext('2d');\n",
        "        context.drawImage(video, 0, 0, 640, 480);\n",
        "        return captureCanvas.toDataURL('image/jpeg', 0.6);\n",
        "    }\n",
        "\n",
        "    // Function to draw boxes back onto the live video\n",
        "    window.drawDetections = function(imgData) {\n",
        "        const canvas = document.getElementById('overlay-canvas');\n",
        "        const ctx = canvas.getContext('2d');\n",
        "        const img = new Image();\n",
        "        img.onload = function() {\n",
        "            ctx.clearRect(0, 0, 640, 480);\n",
        "            ctx.drawImage(img, 0, 0);\n",
        "        };\n",
        "        img.src = imgData;\n",
        "    }\n",
        "\n",
        "    streamVideo();\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "def bytes_to_js_image(annotated_frame):\n",
        "    \"\"\"Converts the OpenCV frame with boxes into a format JS can draw.\"\"\"\n",
        "    # We make the background transparent so only the boxes show up on top of the webcam\n",
        "    _, buffer = cv2.imencode('.png', annotated_frame)\n",
        "    encoded_string = b64encode(buffer).decode('utf-8')\n",
        "    return f'data:image/png;base64,{encoded_string}'\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    return cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "# --- EXECUTION ---\n",
        "start_live_stream()\n",
        "print(\"Starting live real-time detection...\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        # 1. Grab frame from JS\n",
        "        js_reply = eval_js('window.getFrame()')\n",
        "        if not js_reply: break\n",
        "\n",
        "        # 2. Process with YOLO\n",
        "        frame = js_to_image(js_reply)\n",
        "        results = model.predict(frame, conf=0.4, verbose=False)\n",
        "\n",
        "        # 3. Create a blank transparent image for the boxes\n",
        "        # This makes it look like the boxes are floating on your webcam\n",
        "        ann_frame = np.zeros((480, 640, 4), dtype=np.uint8)\n",
        "\n",
        "        # Draw results onto the transparent frame\n",
        "        # We manually extract boxes to keep the background clear\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                label = f'{model.names[cls]} {conf:.2f}'\n",
        "\n",
        "                # Draw the rectangle and label on the transparent image\n",
        "                cv2.rectangle(ann_frame, (x1, y1), (x2, y2), (0, 255, 0, 255), 2)\n",
        "                cv2.putText(ann_frame, label, (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0, 255), 2)\n",
        "\n",
        "        # 4. Send the boxes back to the JS overlay\n",
        "        js_overlay = bytes_to_js_image(ann_frame)\n",
        "        eval_js(f'window.drawDetections(\"{js_overlay}\")')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Stopped: {e}\")"
      ],
      "metadata": {
        "id": "TQ3msthBjUDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}