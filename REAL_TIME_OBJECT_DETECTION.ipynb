{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## üëÅÔ∏è Real-Time Object Detection with YOLOv8\n",
        "\n",
        "YOLO (You Only Look Once) changed the computer vision landscape by treating detection as a **single regression problem** rather than a classification task performed on thousands of window crops. We are using **YOLOv8**, the most refined version of the architecture, which utilizes a \"Darknet\" backbone and a C2f (Cross Stage Partial Bottleneck with two convolutions) module for superior feature fusion.\n",
        "\n",
        "### üìì Python Implementation (Jupyter Optimized)"
      ],
      "metadata": {
        "id": "9qLyZLRdexJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cMF6yfgCfnKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import display, Javascript, clear_output\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 1. Initialize YOLOv8\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "def setup_js_webcam():\n",
        "    js = Javascript('''\n",
        "    // We define the function globally immediately\n",
        "    window.takePhoto = async function() {\n",
        "      const div = document.querySelector('#webcam-div') || document.createElement('div');\n",
        "      div.id = 'webcam-div';\n",
        "\n",
        "      const video = document.querySelector('#webcam-video') || document.createElement('video');\n",
        "      video.id = 'webcam-video';\n",
        "\n",
        "      if (!video.srcObject) {\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        video.style.display = 'block';\n",
        "        video.width = 640;\n",
        "        video.height = 480;\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        await video.play();\n",
        "      }\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = 640;\n",
        "      canvas.height = 480;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "      return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    };\n",
        "\n",
        "    // Signal that the script has loaded\n",
        "    window.webcamReady = true;\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    return cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "# --- EXECUTION ---\n",
        "setup_js_webcam()\n",
        "\n",
        "print(\"Waiting for browser to initialize webcam...\")\n",
        "# 2. THE HANDSHAKE: Wait until JS confirms it's ready\n",
        "for i in range(10):\n",
        "    try:\n",
        "        if eval_js('window.webcamReady'):\n",
        "            print(\"Webcam is ready!\")\n",
        "            break\n",
        "    except:\n",
        "        time.sleep(1)\n",
        "        if i == 9:\n",
        "            print(\"Error: Handshake failed. Please check browser permissions.\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        js_reply = eval_js('window.takePhoto()')\n",
        "        if not js_reply: break\n",
        "\n",
        "        frame = js_to_image(js_reply)\n",
        "        results = model.predict(frame, conf=0.5, verbose=False)\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        cv2_imshow(annotated_frame)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Status: {e}\")"
      ],
      "metadata": {
        "id": "fluiEvypie5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "from IPython.display import display, Javascript, HTML\n",
        "import PIL.Image\n",
        "import io\n",
        "\n",
        "# 1. Initialize YOLOv8\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "def start_live_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "\n",
        "    async function createDom() {\n",
        "        if (div !== null) return;\n",
        "\n",
        "        div = document.createElement('div');\n",
        "        div.style.position = 'relative';\n",
        "\n",
        "        video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        video.width = 640;\n",
        "        video.height = 480;\n",
        "        video.setAttribute('playsinline', '');\n",
        "        video.id = 'video-feed';\n",
        "\n",
        "        // This canvas will sit on top of the video to show detection boxes\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.style.position = 'absolute';\n",
        "        canvas.style.left = '0';\n",
        "        canvas.style.top = '0';\n",
        "        canvas.width = 640;\n",
        "        canvas.height = 480;\n",
        "        canvas.id = 'overlay-canvas';\n",
        "\n",
        "        div.appendChild(video);\n",
        "        div.appendChild(canvas);\n",
        "        document.body.appendChild(div);\n",
        "\n",
        "        captureCanvas = document.createElement('canvas');\n",
        "        captureCanvas.width = 640;\n",
        "        captureCanvas.height = 480;\n",
        "    }\n",
        "\n",
        "    async function streamVideo() {\n",
        "        await createDom();\n",
        "        stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        window.videoStream = stream;\n",
        "    }\n",
        "\n",
        "    // Function to capture a frame and send to Python\n",
        "    window.getFrame = async function() {\n",
        "        const context = captureCanvas.getContext('2d');\n",
        "        context.drawImage(video, 0, 0, 640, 480);\n",
        "        return captureCanvas.toDataURL('image/jpeg', 0.6);\n",
        "    }\n",
        "\n",
        "    // Function to draw boxes back onto the live video\n",
        "    window.drawDetections = function(imgData) {\n",
        "        const canvas = document.getElementById('overlay-canvas');\n",
        "        const ctx = canvas.getContext('2d');\n",
        "        const img = new Image();\n",
        "        img.onload = function() {\n",
        "            ctx.clearRect(0, 0, 640, 480);\n",
        "            ctx.drawImage(img, 0, 0);\n",
        "        };\n",
        "        img.src = imgData;\n",
        "    }\n",
        "\n",
        "    streamVideo();\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "def bytes_to_js_image(annotated_frame):\n",
        "    \"\"\"Converts the OpenCV frame with boxes into a format JS can draw.\"\"\"\n",
        "    # We make the background transparent so only the boxes show up on top of the webcam\n",
        "    _, buffer = cv2.imencode('.png', annotated_frame)\n",
        "    encoded_string = b64encode(buffer).decode('utf-8')\n",
        "    return f'data:image/png;base64,{encoded_string}'\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    return cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "# --- EXECUTION ---\n",
        "start_live_stream()\n",
        "print(\"Starting live real-time detection...\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        # 1. Grab frame from JS\n",
        "        js_reply = eval_js('window.getFrame()')\n",
        "        if not js_reply: break\n",
        "\n",
        "        # 2. Process with YOLO\n",
        "        frame = js_to_image(js_reply)\n",
        "        results = model.predict(frame, conf=0.4, verbose=False)\n",
        "\n",
        "        # 3. Create a blank transparent image for the boxes\n",
        "        # This makes it look like the boxes are floating on your webcam\n",
        "        ann_frame = np.zeros((480, 640, 4), dtype=np.uint8)\n",
        "\n",
        "        # Draw results onto the transparent frame\n",
        "        # We manually extract boxes to keep the background clear\n",
        "        for result in results:\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                label = f'{model.names[cls]} {conf:.2f}'\n",
        "\n",
        "                # Draw the rectangle and label on the transparent image\n",
        "                cv2.rectangle(ann_frame, (x1, y1), (x2, y2), (0, 255, 0, 255), 2)\n",
        "                cv2.putText(ann_frame, label, (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0, 255), 2)\n",
        "\n",
        "        # 4. Send the boxes back to the JS overlay\n",
        "        js_overlay = bytes_to_js_image(ann_frame)\n",
        "        eval_js(f'window.drawDetections(\"{js_overlay}\")')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Stopped: {e}\")"
      ],
      "metadata": {
        "id": "TQ3msthBjUDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}